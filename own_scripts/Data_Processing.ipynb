{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['nnUNet_raw'] = \"/content/drive/MyDrive/TFM/raw\"\n",
        "os.environ['nnUNet_preprocessed'] =  \"/content/drive/MyDrive/TFM/preprocessed\"\n",
        "os.environ['nnUNet_results'] = \"/content/drive/MyDrive/TFM/results\""
      ],
      "metadata": {
        "id": "nR8P8P8ZoaBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing\n",
        "\n",
        "During my TFM, I had to modify the Dataset several times for logistical reasons or due to a bad performance of the U-Net. Here we describe the different pieces of code used for that purpose."
      ],
      "metadata": {
        "id": "qyHoCwLWg1Qy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging the three masks in one file\n",
        "Originally, the masks where separated in three masks:\n",
        "1. A mask with all the lesions: SELs, non-SELs and possible SELs. All of them with a mask value of 1.\n",
        "2. A mask with only the non-SELs.\n",
        "3. A mask with only the SELs.\n",
        "\n",
        "This code creates a nifti with the three of the masks."
      ],
      "metadata": {
        "id": "K1FFJLu0iRuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "ssd_path = os.path.join(os.sep, \"Volumes\", \"SSD-TOSHIBA\")\n",
        "\n",
        "all_lesions = sorted(glob.glob(os.path.join(ssd_path, \"Dataset TFM\", \"labelsTr\", \"rMSVIS_*_T1_lesion_mask.nii.gz\")))\n",
        "masks_SEL = sorted(glob.glob(os.path.join(ssd_path, \"Dataset TFM\", \"labelsTr\", \"rMSVIS_*_T1_SELs_mask.nii.gz\")))\n",
        "masks_nonSEL = sorted(glob.glob(os.path.join(ssd_path, \"Dataset TFM\", \"labelsTr\", \"rMSVIS_*_T1_nonSELs_mask.nii.gz\")))"
      ],
      "metadata": {
        "id": "80VboiZ7kbKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nifti(path):\n",
        "    return nib.load(path).get_fdata()\n",
        "\n",
        "def extract_value_from_string(file_name):\n",
        "    # Define the pattern using regular expression\n",
        "    pattern = r\"rMSVIS_(\\d+)_T1_nonSELs_mask.nii.gz\"\n",
        "\n",
        "    # Use regular expression to find the value\n",
        "    match = re.search(pattern, file_name)\n",
        "\n",
        "    if match:\n",
        "        extracted_value = match.group(1)\n",
        "        return extracted_value\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "for sel, no_sel, full in zip(masks_SEL, masks_nonSEL, all_lesions):\n",
        "    variable = extract_value_from_string(os.path.basename(no_sel))\n",
        "\n",
        "    # If we already have the mask called \"all_labels_mask\" we skip this iteration\n",
        "    if os.path.exists(os.path.join(ssd_path,  \"Dataset TFM\", \"labelsTr\", f\"rMSVIS_{variable}_T1_all_labels_mask.nii.gz\")):\n",
        "        continue\n",
        "\n",
        "    print(f\"Working with {variable}\")\n",
        "\n",
        "    sel_mask = load_nifti(sel)\n",
        "    no_sel_mask = load_nifti(no_sel)\n",
        "    full_mask = load_nifti(full)\n",
        "\n",
        "    # Convert in zero the values in full mask present in sel mask\n",
        "    full_mask[sel_mask != 0] = 0\n",
        "    # Convert in zero the values in full mask present in no sel mask\n",
        "    full_mask[no_sel_mask != 0] = 0\n",
        "\n",
        "    # We create a mask with all labels at the same time\n",
        "    all_labels = sel_mask + no_sel_mask + full_mask\n",
        "\n",
        "    # Store the new mask\n",
        "    new_mask = nib.Nifti1Image(full_mask, affine=None)\n",
        "    all_labels_mask = nib.Nifti1Image(all_labels, affine=None)\n",
        "    nib.save(new_mask, os.path.join(ssd_path,  \"Dataset TFM\", \"labelsTr\", f\"rMSVIS_{variable}_T1_possibleSELs_mask.nii.gz\"))\n",
        "    nib.save(all_labels_mask, os.path.join(ssd_path,  \"Dataset TFM\", \"labelsTr\", f\"rMSVIS_{variable}_T1_all_labels_mask.nii.gz\"))\n",
        "\n",
        "    print(f\"The unique values in the mask are: {np.unique(all_labels)}\")\n",
        "    print(f\"Done with {variable}\")"
      ],
      "metadata": {
        "id": "NdBVh_aCBvcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = sorted(glob.glob(os.path.join(ssd_path, \"Dataset TFM\", \"labelsTr\", \"rMSVIS_*_T1_all_labels_mask.nii.gz\")))\n",
        "imgs = sorted(glob.glob(os.path.join(ssd_path, \"Dataset TFM\", \"imagesTr\", \"rMSVIS_*_*_T1.nii.gz\")))\n"
      ],
      "metadata": {
        "id": "MSV4hrvbBxvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We store the images in the folder DatasetPrepared/Images\n",
        "from collections import defaultdict\n",
        "\n",
        "file_groups = defaultdict(list)\n",
        "\n",
        "# Extract and group files based on the alphanumeric (\\w) part\n",
        "for file in imgs:\n",
        "    match = re.search(r'rMSVIS_(\\w+)_([0-9]{2})_T1.nii.gz', file)\n",
        "    if match:\n",
        "        id, timepoint = int(match.group(1)), int(match.group(2))\n",
        "        file_groups[id].append((timepoint, file))\n",
        "\n",
        "# Sort and rename the files within each group\n",
        "for id, files in file_groups.items():\n",
        "    files.sort(key=lambda x: x[0])  # Sort by the timepoint part\n",
        "\n",
        "    # Renaming logic\n",
        "    for index, (timepoint, file) in enumerate(files):\n",
        "        new_id = \"{:03d}\".format(id)\n",
        "        new_timepoint = \"{:04d}\".format(index)\n",
        "        new_name = f\"rMSVIS_{new_id}_{new_timepoint}.nii.gz\"\n",
        "        #os.rename(file, os.path.join(\"DatasetPrepared\", \"Images\", new_name))\n",
        "        os.rename(file, os.path.join(ssd_path, \"Dataset TFM\", \"imagesTr\", new_name))"
      ],
      "metadata": {
        "id": "i3yTF0EVB8u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We store the masks in the folder DatasetPrepared/Masks\n",
        "file_groups = defaultdict(list)\n",
        "\n",
        "for file in all_labels:\n",
        "    match = re.search(r'rMSVIS_(\\w+)_T1_all_labels_mask.nii.gz', file)\n",
        "    if match:\n",
        "        id = int(match.group(1))\n",
        "        file_groups[id].append(file)\n",
        "\n",
        "# Sort and rename the files within each group\n",
        "for id, files in file_groups.items():\n",
        "    files.sort(key=lambda x: x[0])  # Sort by the timepoint part\n",
        "\n",
        "    # Renaming logic\n",
        "    for index, file in enumerate(files):\n",
        "        new_id = \"{:03d}\".format(id)\n",
        "        new_name = f\"rMSVIS_{new_id}.nii.gz\"\n",
        "        #os.rename(file, os.path.join(\"DatasetPrepared\", \"Masks\", new_name))\n",
        "        os.rename(file, os.path.join(ssd_path, \"Dataset TFM\", \"labelsTr\", new_name))"
      ],
      "metadata": {
        "id": "f-cyXl55B_R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nifti to NRRD (check in Macbook)\n"
      ],
      "metadata": {
        "id": "C_hcMyFDk18a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The framework of nnU-Net was giving problems to read the dataset in Nifti format due to the lack of concordance between origins and orientations in the different timepoints or subjects."
      ],
      "metadata": {
        "id": "_0VMAqFfE7z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itk\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#Â Images in SSD\n",
        "ssd_path = \"/Volumes/SSD-TOSHIBA/Dataset TFM\"\n",
        "images = sorted(glob.glob(os.path.join(ssd_path, \"imagesTr copia\", \"*.nii.gz\")))\n",
        "masks = sorted(glob.glob(os.path.join(ssd_path, \"labelsTr copia\", \"*.nii.gz\")))\n",
        "\n"
      ],
      "metadata": {
        "id": "cKMUqOIHhTJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We store the nifti images into NRRD\n",
        "\n",
        "for i in range(len(images)):\n",
        "    img = itk.imread(images[i])\n",
        "    img_np = itk.array_from_image(img)\n",
        "    img_itk = itk.GetImageFromArray(img_np)\n",
        "    itk.imwrite(img_itk, images[i].replace(\".nii.gz\", \".nrrd\"))"
      ],
      "metadata": {
        "id": "5iiDV8Fchjoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We store the nifti masks into NRRD\n",
        "for i in range(len(masks)):\n",
        "    img = itk.imread(masks[i])\n",
        "    img_np = itk.array_from_image(img)\n",
        "    img_itk = itk.GetImageFromArray(img_np)\n",
        "    itk.imwrite(img_itk, masks[i].replace(\".nii.gz\", \".nrrd\"))"
      ],
      "metadata": {
        "id": "AXfrJ_hPE4e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the possible SEL to non-SEL and substraction between follow-up 2 and screening.\n",
        "The U-Net presented low values on the validation Dice, as well as in the training. Thus, the possible SELs where changed to non-SEL."
      ],
      "metadata": {
        "id": "AKnEpuWZlZRs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp4Et31-gzZF"
      },
      "outputs": [],
      "source": [
        "# Directory to Dataset111\n",
        "dataset_dir = os.path.join(os.environ[\"nnUNet_preprocessed\"], \"Dataset111_SEL\",\n",
        "                           \"nnUNetPlans_2d\")\n",
        "\n",
        "segs = glob.glob(os.path.join(dataset_dir, \"rMSVIS_*_seg.npy\"))\n",
        "segs.sort()\n",
        "\n",
        "pattern = re.compile(r'rMSVIS_\\d+\\.npy')\n",
        "imgs = [file for file in glob.glob(os.path.join(dataset_dir, \"*\")) if pattern.match(os.path.basename(file))]\n",
        "imgs.sort()\n",
        "\n",
        "dataset_path = os.path.join(os.environ[\"nnUNet_raw\"], \"Dataset115_Substract-binary-possibleSEL2noSEL\")\n",
        "\n",
        "if not os.path.exists(os.path.join(dataset_path, \"imagesTr\")):\n",
        "  os.makedirs(os.path.join(dataset_path, \"imagesTr\"))\n",
        "\n",
        "if not os.path.exists(os.path.join(dataset_path, \"labelsTr\")):\n",
        "  os.makedirs(os.path.join(dataset_path, \"labelsTr\"))\n",
        "\n",
        "\n",
        "for seg, img in zip(segs, imgs):\n",
        "  image = np.load(os.path.join(img))\n",
        "  segmentation = np.load(os.path.join(seg))\n",
        "  segmentation[segmentation==-1] = 0\n",
        "  segmentation[segmentation==1] = 1\n",
        "  segmentation[segmentation==2] = 1\n",
        "  segmentation[segmentation==3] = 2\n",
        "  substracted_img = image[2] - image[0]\n",
        "\n",
        "  sustract_name = os.path.splitext(os.path.basename(img))[0] + \"_0001\" + \".nii.gz\"\n",
        "  sustract_path = os.path.join(dataset_path, \"imagesTr\", sustract_name)\n",
        "  img_name = os.path.splitext(os.path.basename(img))[0] + \"_0000\" + \".nii.gz\"\n",
        "  img_path = os.path.join(dataset_path, \"imagesTr\", img_name)\n",
        "\n",
        "  seg_name = os.path.splitext(os.path.basename(seg))[0] + \".nii.gz\"\n",
        "  seg_path = os.path.join(dataset_path, \"labelsTr\", seg_name)\n",
        "  seg_path = seg_path.replace(\"_seg\", \"\")\n",
        "  nib.save(nib.Nifti1Image(substracted_img, affine=np.eye(4)), sustract_path)\n",
        "  nib.save(nib.Nifti1Image(image[0], affine=np.eye(4)), img_path)\n",
        "  nib.save(nib.Nifti1Image(segmentation[0], affine=np.eye(4)), seg_path)\n",
        "\n",
        "  print(f\"Case {img_name} done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patches (using only SEL and non-SEL)\n",
        "With the aim of improving the Dice, we create patches around each of the lesions. The patches are all re-formatted to 32x32x32."
      ],
      "metadata": {
        "id": "uBdDm96lqOWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path2imgs = os.path.join(os.environ['nnUNet_raw'], \"Dataset115_Substract-binary-possibleSEL2noSEL\", \"imagesTr\")\n",
        "path2labels = os.path.join(os.environ['nnUNet_raw'], \"Dataset115_Substract-binary-possibleSEL2noSEL\", \"labelsTr\")\n",
        "\n",
        "segs = glob.glob(os.path.join(path2labels, \"rMSVIS*.nii.gz\"))\n",
        "img_0 = glob.glob(os.path.join(path2imgs, \"rMSVIS_*_0000.nii.gz\"))\n",
        "img_1 = glob.glob(os.path.join(path2imgs, \"rMSVIS_*_0001.nii.gz\"))\n",
        "\n",
        "def crop_around_segmentation(image_data, substract_data, segmentation_data, patch_size=(32, 32, 32)):\n",
        "    # Find connected components in the segmentation mask\n",
        "    labeled_segments, num_labels = ndimage.label(segmentation_data)\n",
        "\n",
        "    # Crop patches around each lesion\n",
        "    patches_img = []\n",
        "    patches_seg = []\n",
        "    patches_substract = []\n",
        "    i = 0\n",
        "    for label in range(1, num_labels + 1):\n",
        "        # Extract coordinates of the current lesion\n",
        "        indices = np.where(labeled_segments == label)\n",
        "\n",
        "        # Calculate bounding box around the lesion\n",
        "        min_x, min_y, min_z = np.min(indices, axis=1)\n",
        "        max_x, max_y, max_z = np.max(indices, axis=1)\n",
        "        if i == 0:\n",
        "          print(f\"{min_x}, {min_y}, {min_z}\")\n",
        "          print(f\"{max_x}, {max_y}, {max_z}\")\n",
        "          i = 1\n",
        "\n",
        "        # Crop the patch around the lesion\n",
        "        patch_img = image_data[min_x:max_x + 1, min_y:max_y + 1, min_z:max_z + 1]\n",
        "        patch_seg = segmentation_data[min_x:max_x + 1, min_y:max_y + 1, min_z:max_z + 1]\n",
        "        patch_substract = substract_data[min_x:max_x + 1, min_y:max_y + 1, min_z:max_z + 1]\n",
        "        # Resize the patch to the specified size\n",
        "        patch_img = ndimage.zoom(patch_img, np.array(patch_size) / patch_img.shape, order=0)\n",
        "        patch_seg = ndimage.zoom(patch_seg, np.array(patch_size) / patch_seg.shape, order=0)\n",
        "        patch_substract = ndimage.zoom(patch_substract, np.array(patch_size) / patch_substract.shape, order=0)\n",
        "\n",
        "        # Append the patch to the list\n",
        "        patches_img.append(patch_img)\n",
        "        patches_seg.append(patch_seg)\n",
        "        patches_substract.append(patch_substract)\n",
        "\n",
        "    return patches_img, patches_substract, patches_seg"
      ],
      "metadata": {
        "id": "A0xEE16cp_ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segs = glob.glob(os.path.join(path2labels, \"rMSVIS*.nii.gz\"))\n",
        "img_0 = glob.glob(os.path.join(path2imgs, \"rMSVIS_*_0000.nii.gz\"))\n",
        "img_1 = glob.glob(os.path.join(path2imgs, \"rMSVIS_*_0001.nii.gz\"))\n",
        "\n",
        "# We declare the paths where we will save the patches\n",
        "path2patches = os.path.join(os.environ['nnUNet_raw'], \"Dataset116_Patches\")\n",
        "path2patches_img = os.path.join(path2patches, \"imagesTr\")\n",
        "path2patches_seg = os.path.join(path2patches, \"labelsTr\")\n",
        "\n",
        "# We create the folders if they don't exist\n",
        "if not os.path.exists(path2patches_img):\n",
        "  os.makedirs(path2patches_img)\n",
        "\n",
        "if not os.path.exists(path2patches_seg):\n",
        "    os.makedirs(path2patches_seg)\n",
        "\n",
        "\n",
        "i = 0\n",
        "for i0, i1, seg in zip(img_0, img_1, segs):\n",
        "    if i == 0:\n",
        "        print(i0)\n",
        "        print(i1)\n",
        "        print(seg)\n",
        "    image_0 = nib.load(i0).get_fdata()\n",
        "    image_1 = nib.load(i1).get_fdata()\n",
        "    segmentation = nib.load(seg).get_fdata()\n",
        "\n",
        "    patches_img_0, patches_img_1, patches_seg = crop_around_segmentation(image_0, image_1, segmentation)\n",
        "    # We save the patches with a pattern that will go from 000 to 9999.\n",
        "    # Series will maintain their name: 0000 for image_0, 0001 for image_1\n",
        "\n",
        "    for patch_img_0, patch_img_1, patch_seg in zip(patches_img_0, patches_img_1, patches_seg):\n",
        "        patch_name = \"patch_\" + str(i).zfill(3) + \"_0000\" \".nii.gz\"\n",
        "        patch_path_img_0 = os.path.join(path2patches_img, patch_name)\n",
        "        patch_path_img_1 = os.path.join(path2patches_img, patch_name.replace(\"_0000\", \"_0001\"))\n",
        "        patch_path_seg = os.path.join(path2patches_seg, patch_name)\n",
        "\n",
        "        nib.save(nib.Nifti1Image(patch_img_0, affine=np.eye(4)), patch_path_img_0)\n",
        "        nib.save(nib.Nifti1Image(patch_img_1, affine=np.eye(4)), patch_path_img_1)\n",
        "        nib.save(nib.Nifti1Image(patch_seg, affine=np.eye(4)), patch_path_seg)\n",
        "\n",
        "        print(f\"Patch {patch_name} done\")\n",
        "\n",
        "        i += 1\n"
      ],
      "metadata": {
        "id": "__s_4NnHsZC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since there are too much cases (>5000), we select 200: 100 for non-SEL and 100 for SEL.\n",
        "\n",
        "# From the cases with label = 1 and the cases with label = 2, we will select 100 cases for each of them.\n",
        "path2patches_img = os.path.join(path2patches, \"imagesTr\")\n",
        "path2patches_seg = os.path.join(path2patches, \"labelsTr\")\n",
        "\n",
        "patches_0 = glob.glob(os.path.join(path2patches_img, \"patch_*_0000.nii.gz\"))\n",
        "patches_1 = glob.glob(os.path.join(path2patches_img, \"patch_*_0001.nii.gz\"))\n",
        "patches_0.sort()\n",
        "patches_1.sort()\n",
        "\n",
        "patches_seg = glob.glob(os.path.join(path2patches_seg, \"patch_*.nii.gz\"))\n",
        "patches_seg.sort()\n",
        "\n",
        "path2patches_200 = os.path.join(os.environ['nnUNet_raw'], \"Dataset118_Patches_200\")\n",
        "path2patches_img_200 = os.path.join(path2patches_200, \"imagesTr\")\n",
        "path2patches_seg_200 = os.path.join(path2patches_200, \"labelsTr\")\n",
        "\n",
        "\n",
        "if not os.path.exists(path2patches_img_200):\n",
        "    os.makedirs(path2patches_img_200)\n",
        "\n",
        "if not os.path.exists(path2patches_seg_200):\n",
        "    os.makedirs(path2patches_seg_200)\n",
        "\n",
        "\n",
        "N=100\n",
        "# We will select 383 cases with label = 1 and 500 cases with label = 2\n",
        "i = 0\n",
        "j = 0\n",
        "k = 0\n",
        "\n",
        "for patch_0, patch_1, patch_seg in zip(patches_0, patches_1, patches_seg):\n",
        "    segmentation = nib.load(patch_seg).get_fdata()\n",
        "    unique_values = np.unique(segmentation)\n",
        "\n",
        "    if 1 in unique_values and 2 in unique_values:\n",
        "        continue\n",
        "    elif 1 in unique_values and 2 not in unique_values and i < N:\n",
        "        patch_name = \"patch_\" + str(k).zfill(3) + \"_0000.nii.gz\"\n",
        "        patch_seg_name = \"patch_\" + str(k).zfill(3) + \".nii.gz\"\n",
        "        patch_path_img = os.path.join(path2patches_img_200, patch_name)\n",
        "        patch_path_seg = os.path.join(path2patches_seg_200, patch_seg_name)\n",
        "\n",
        "        #nib.save(nib.load(patch_0), patch_path_img)\n",
        "        #nib.save(nib.load(patch_1), patch_path_img.replace(\"_0000\", \"_0001\"))\n",
        "        nib.save(nib.load(patch_seg), patch_path_seg)\n",
        "\n",
        "        print(f\"Patch {patch_name} done as label 1\")\n",
        "\n",
        "        i += 1\n",
        "        k += 1\n",
        "    elif 2 in unique_values and 1 not in unique_values and j < N:\n",
        "        patch_name = \"patch_\" + str(k).zfill(3) + \"_0000.nii.gz\"\n",
        "        patch_seg_name = \"patch_\" + str(k).zfill(3) + \".nii.gz\"\n",
        "        patch_path_img = os.path.join(path2patches_img_200, patch_name)\n",
        "        patch_path_seg = os.path.join(path2patches_seg_200, patch_seg_name)\n",
        "\n",
        "        #nib.save(nib.load(patch_0), patch_path_img)\n",
        "        #nib.save(nib.load(patch_1), patch_path_img.replace(\"_0000\", \"_0001\"))\n",
        "        nib.save(nib.load(patch_seg), patch_path_seg)\n",
        "\n",
        "        print(f\"Patch {patch_name} done as label 2\")\n",
        "\n",
        "        j += 1\n",
        "        k += 1\n",
        "    elif i == N and j == N:\n",
        "        break\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "uQH68i8_srPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}